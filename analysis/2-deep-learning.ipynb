{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "from bc.beats import get_beat_bank\n",
    "from bc.plot import plot_beat, plot_four_beats\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "\n",
    "base_dir = os.path.abspath('..')\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "\n",
    "# Table of record names and the beat types they contain\n",
    "beat_table = pd.read_csv(os.path.join(data_dir, 'beat-types.csv'), dtype={'record':object})\n",
    "beat_table.set_index('record', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load beats with fixed width.\n",
    "n_beats, n_centers = get_beat_bank(data_dir=data_dir, beat_table=beat_table,\n",
    "                                   wanted_type='N', filter=True, fixed_width=240)\n",
    "l_beats, l_centers = get_beat_bank(data_dir=data_dir, beat_table=beat_table,\n",
    "                                   wanted_type='L' ,filter=True, fixed_width=240)\n",
    "r_beats, r_centers = get_beat_bank(data_dir=data_dir, beat_table=beat_table,\n",
    "                                   wanted_type='R', filter=True, fixed_width=240)\n",
    "v_beats, v_centers = get_beat_bank(data_dir=data_dir, beat_table=beat_table,\n",
    "                                   wanted_type='V', filter=True, fixed_width=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now all beats have the same number of samples\n",
    "plot_four_beats(beats=[n_beats[0], l_beats[0], r_beats[0], v_beats[0]],\n",
    "                centers=[n_centers[0], l_centers[0], r_centers[0], v_centers[0]],\n",
    "                seconds=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how a beat will look as an M x 2 image\n",
    "# Stretch a beat channelwise just for visualization\n",
    "stretch_factor = 20\n",
    "beat_image = np.empty([n_beats[0].shape[1] * stretch_factor, n_beats[0].shape[0]])\n",
    "for i in range(stretch_factor):\n",
    "    for ch in range(2):\n",
    "        beat_image[ch*stretch_factor + i, :] = n_beats[0][:, ch]\n",
    "plt.figure()\n",
    "plt.imshow(beat_image, cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all beats into a large tensor\n",
    "beats_all = torch.from_numpy(\n",
    "    np.array(n_beats+ l_beats + r_beats + v_beats).transpose(0, 2, 1).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = torch.tensor([0]*len(n_beats) + [1]*len(l_beats)\n",
    "                            + [2]*len(r_beats) + [3]*len(v_beats), dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network structure\n",
    "class BeatNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Reference : https://pytorch.org/docs/master/nn.html#conv1d\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BeatNet, self).__init__()\n",
    "        # input is 2 channel ecg\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=4, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=4, out_channels=8, kernel_size=3)\n",
    "        # maxpool function\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(8 * 58, 12)\n",
    "        # Final fully connected layer \n",
    "        self.fc2 = nn.Linear(12, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Reshape input data for fully connected layer\n",
    "        # Question: Why is this 8 * 58? Explain the steps.\n",
    "        x = x.view(-1, 8 * 58)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Dataset class to iterate the beats\n",
    "class BeatDataset(Dataset):\n",
    "    def __init__(self, beats, labels):\n",
    "        self.beats = beats\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        x = self.beats[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data loader.\n",
    "beatloader = DataLoader(dataset=BeatDataset(beats_all, labels_all),\n",
    "                        shuffle=True, batch_size=4, num_workers=2)\n",
    "\n",
    "for i, data in enumerate(beatloader, 0):        \n",
    "    #Get inputs\n",
    "    inputs, labels = data\n",
    "    print(i, inputs.shape, labels)\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train_net(net, batch_size, n_epochs, learning_rate):\n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size=\", batch_size)\n",
    "    print(\"epochs=\", n_epochs)\n",
    "    print(\"learning_rate=\", learning_rate)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Create the loader instance to load our beat data\n",
    "    beatloader = DataLoader(dataset=BeatDataset(beats_all, labels_all),\n",
    "                            shuffle=True, batch_size=batch_size)\n",
    "    # Create the loss function - cross entropy loss\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    # Create the optimizer function - stochastic gradient descent\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    # The number of batches per epoch is the length of data divided by the batch size\n",
    "    n_batches = len(beatloader)\n",
    "    start_time = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(beatloader, 0):\n",
    "            # Get inputs\n",
    "            inputs, labels = data\n",
    "            # Wrap them in a Variable object\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass, backward pass, optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_fun(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print('Training finished in {:.2f}s'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_all.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatnet = BeatNet()\n",
    "\n",
    "beatnet.to(device)\n",
    "beats_all = beats_all.to(device)\n",
    "labels_all = labels_all.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 4\n",
      "epochs= 2\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Training finished in 40.83s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_net(beatnet, batch_size=4, n_epochs=2, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(dataset=BeatDataset(beats_all, labels_all),\n",
    "                            shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "incomplete format",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-75e8658fddef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m print('Accuracy of the network on the {} test items: {.2f}%' % (\n\u001b[0;32m---> 12\u001b[0;31m     100 * correct / total))\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: incomplete format"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data, label in testloader:\n",
    "#     data, label = beats_all[i], labels_all[i]\n",
    "    outputs = beatnet(data)\n",
    "    _, y_pred = torch.max(outputs, 1)\n",
    "    total += label.size(0)\n",
    "    correct += (y_pred == label).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the {} test items: {.2f}%'.format(\n",
    "    len(testloader), 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 21602 test items: 99.34%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the network on the {} test items: {:.2f}%'.format(\n",
    "    len(testloader), 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.from_numpy(np.array(v_beats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beatnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image batch size is torch.Size([4, 3, 32, 32])\n",
    "# So our ecg batch should be [4, 2, 240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_beats[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty([4,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.transpose((0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beats_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1060 6GB'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
